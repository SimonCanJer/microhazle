# microhazle
The project demostrates a  Hazelcast based mechanism to communicate  services for SOA and microservices architecture using simple queue pooling. 
The sample version of project is extracted  from previous versions which have been designed to build dustributed worklfow integrating microservices are connected over Hazelcast where a bit another mechanism of invoke was used.
 The idea and the main motivation is to expand very simple and wellknown mechanism of asynchronous operations and threads communication over queues on to IPC, integrating distribuuted componnets. The only difference is add(..) and take(..) are called by sender and consumer in different processes. Hazelcast provides the nice mechanism. 
 Hazelcast is an in process data grid, which does not require additional installs and, fortunatelly provides collections, caches, queues which neded to build distributed asynchronous/parallel processing, data caching and populating. The mechsnims enable to create event driven distributed workflow  and realization  of microservices model, where microservices are invoked over event fired, which is realized as put and consume messages in queues. At the same time Hazelcast provides collections as maps and set, which enable developer to share data between worklfow components. And there is yet a remarkable feature of Hazelcast core: all its collections, and other objects exists per Hazelcast instance which is distinguished by name. Thus, number of processes/services can share objects of the same instance of Hazelcast, when Hazelcast performs transparent discovery of other components of grid, which is related to the same instance. No additional discovery framework required. Furthermore, configuring mechanism provides developer switch on discovery components are dedicated  to AWS, Kubernetes and another cloud inherent mechanisms.
 In this project workflow and furthering it event mechanism are realized using the IQueue distributed collection of Hazelcast with a name, which corresponds to type of processed events. The IQueue instances with the same name are created in any JVM of worklfow which is associated with related Hazelcast instance. So add(..) in sender's JVM will be handled by take(..) in consumer JVM.
 Thus, workflow mechanism is leveraged by sending and consumning messages of predefinded types, using IQueue with corresponding name and a looping threads polling the queue.Due to the S (of SOLID) paradigm normally a process should consume a one type of events (have one listened IQueue). Number of destination IQueues,to where event/request to be send, is not limited. The important is that ratio :IQueue is n:m for any request type. It means that number of instanes of JVM can (and must) listen for the same type of request. Hazelcast guarantees that a message will be taken from queue (and processed) only in one instance of JVM. It is simple and transparent Load Ballancing- just start new process, which handles the same type of message in the same instance of Hazelcast(do not confuse which instance of objects) and requests will be sent to it also withoiut any additions.
 In this reaization we have used messaging (send-reply) communication: in practice it means that consumer anyway will reply to sender (it is not a pure distrubuted model). This way any message is contained in DTO. The DTO contains description of type of event (class usually)-Header, which encapsulated  main transportation information in the DTO, and history (Stack of headers).Whaot is for? It is due to processor, which handles consumed request can send own furthering request inside a worklfow implementation (as a subtask). The Stak of headers simplifies reply forming.
 In order to handle responses we have an additional IQueue in the mechanism:own IQueue is dedicated to get replies and messages, which  are directed to concrete instance of JVM. Unlike IQueues, which are dedicated to listen incoming requests, IQueues, which are dedicated to be listened for responses exist with an unique name. The IQeueue name is the sender address in the header of a message DTO object. The reply will be put (add(..) to queue with this name on another machiens, where consumer got and processed the request and returned an answer.
 The mechanism requires just to define name of a worklfow ( fedaration in our terms), register processors for request /events types. It provides an abstrcat class for processor implementation, which handles main non domain functionality: send furthering request to complete processing of request is being handled, handle reponses, expose result. A concrete realization of a processor should just implement its business logic and declare request, which will be sent for furthering processing in order to complete request hadndling.
 All the processing is done asynchronously. Only atomic reaction of new request or incoming reply is done in one thread. During the request processing either result will be  returned or request will be sent. Response will be processed in another thread asynchronously.In order to support this, container,which serves request processing, keeps information about request, state of processing and provides the information upon request over a processing context.
 Declaration of the requesty which will be sent for furthering processing is necessary in order to verify are the related queues listened. Request will not be accepted if system does not see that is is handled by a consumer instance. Any sending channel has API metod enebling to verify whether a concrete type of request is handled.f
 Request send/Event firing mechanism is supported by a channels mechnanism. A channel which a request will be transmisted over is obtained from API by name of the class of a concrete request. Basically chain of operation of a message sent over a channel ended by IQueue.add(..). The send operation has number of implementations, incluidng callback on response  and Mono based asynchronous invoke
The sample, includes an API emebling to the developed mechanism upon it is included into a Maven project as arctifact (see pom)
The API and implementing classes provides the main possibilties:
- create multi level request message processing mechanisms by providing request handlers per data class with fully automated request dispatch, simply build simple microservices just handling a type of request as message listener. The created mechanism and hazelcast native framework provides hidden instances discovery (by IQueue name); 
- convenient mechanisms for request send and reply, where routing LB is hidden behind the scene;
- data impersonation and sharing among groups of services/microservices, for cross domain session build.
- registrtaion of any end point running on IP address of current JVM and port (ip address is obtained automatically, network interface is selected useing a privided filter/pattern) and populating it accross domain. It can be any type of endpoint. The API provides retrieving a list of end points by service id.
Where the way cans help?
It could be helpful for creation of set of workers/servers/microservices of asynchronous event driven worflow model, where is no need in REST,discovery, LB. caching frameworks.So one framework realy provides all the necessary components of microservice(furthermore- serverless) model of worklfow. No needs, so,  in configuring Zuul, Spring Cloud,Eurica, other discovery framework for REST, configuring if underlaying messaging. Hazelcast discovery mechanism includes objects providing the underlaying discovery of VM in a cluster inside Kubernetes, ASW, GCP environment and does not require additional objects and configirations. It is very pretty from  DevOps point of view: just deliver and  images of worklfow
